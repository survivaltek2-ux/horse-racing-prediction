# Logstash Pipeline Configuration
input {
  # Application logs from Docker containers
  beats {
    port => 5044
  }

  # Syslog input
  syslog {
    port => 5514
  }

  # HTTP input for direct log shipping
  http {
    port => 8080
    codec => json
  }

  # File input for local log files
  file {
    path => "/var/log/app/*.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    codec => json
  }
}

filter {
  # Parse timestamp
  date {
    match => [ "timestamp", "ISO8601" ]
    target => "@timestamp"
  }

  # Add environment information
  mutate {
    add_field => { "environment" => "production-dev" }
    add_field => { "cluster" => "horse-racing-prediction" }
  }

  # Parse application logs
  if [fields][service] == "flask-app" {
    grok {
      match => { 
        "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{DATA:logger}: %{GREEDYDATA:log_message}"
      }
    }

    # Parse Flask request logs
    if [log_message] =~ /^\d+\.\d+\.\d+\.\d+/ {
      grok {
        match => {
          "log_message" => "%{IPORHOST:client_ip} - - \[%{HTTPDATE:request_time}\] \"%{WORD:method} %{URIPATH:path}(?:%{URIPARAM:params})? HTTP/%{NUMBER:http_version}\" %{NUMBER:status_code} %{NUMBER:response_size} \"%{DATA:referrer}\" \"%{DATA:user_agent}\""
        }
      }
      
      mutate {
        convert => { "status_code" => "integer" }
        convert => { "response_size" => "integer" }
      }
    }

    # Parse error logs
    if [level] == "ERROR" {
      mutate {
        add_tag => [ "error" ]
      }
    }

    # Parse warning logs
    if [level] == "WARNING" {
      mutate {
        add_tag => [ "warning" ]
      }
    }
  }

  # Parse Nginx logs
  if [fields][service] == "nginx" {
    grok {
      match => {
        "message" => "%{IPORHOST:client_ip} - %{DATA:user_name} \[%{HTTPDATE:access_time}\] \"%{WORD:method} %{DATA:url} HTTP/%{NUMBER:http_version}\" %{NUMBER:response_code} %{NUMBER:body_sent_bytes} \"%{DATA:referrer}\" \"%{DATA:agent}\" \"%{DATA:x_forwarded_for}\" rt=%{NUMBER:request_time} uct=\"%{DATA:upstream_connect_time}\" uht=\"%{DATA:upstream_header_time}\" urt=\"%{DATA:upstream_response_time}\""
      }
    }

    mutate {
      convert => { "response_code" => "integer" }
      convert => { "body_sent_bytes" => "integer" }
      convert => { "request_time" => "float" }
    }

    # Tag slow requests
    if [request_time] and [request_time] > 2.0 {
      mutate {
        add_tag => [ "slow_request" ]
      }
    }

    # Tag error responses
    if [response_code] and [response_code] >= 400 {
      mutate {
        add_tag => [ "http_error" ]
      }
    }
  }

  # Parse PostgreSQL logs
  if [fields][service] == "postgres" {
    grok {
      match => {
        "message" => "%{TIMESTAMP_ISO8601:timestamp} \[%{NUMBER:pid}\] %{WORD:level}: %{GREEDYDATA:log_message}"
      }
    }

    # Parse slow query logs
    if [log_message] =~ /duration:/ {
      grok {
        match => {
          "log_message" => "duration: %{NUMBER:duration_ms} ms  statement: %{GREEDYDATA:query}"
        }
      }

      mutate {
        convert => { "duration_ms" => "float" }
      }

      # Tag slow queries
      if [duration_ms] and [duration_ms] > 1000 {
        mutate {
          add_tag => [ "slow_query" ]
        }
      }
    }
  }

  # Parse Redis logs
  if [fields][service] == "redis" {
    grok {
      match => {
        "message" => "%{NUMBER:pid}:%{WORD:role} %{TIMESTAMP_ISO8601:timestamp} %{WORD:level} %{GREEDYDATA:log_message}"
      }
    }
  }

  # GeoIP enrichment for client IPs
  if [client_ip] {
    geoip {
      source => "client_ip"
      target => "geoip"
    }
  }

  # User agent parsing
  if [user_agent] {
    useragent {
      source => "user_agent"
      target => "ua"
    }
  }

  # Remove unnecessary fields
  mutate {
    remove_field => [ "host", "agent", "ecs", "input", "log" ]
  }
}

output {
  # Send to Elasticsearch
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "logstash-%{[fields][service]}-%{+YYYY.MM.dd}"
    template_name => "logstash"
    template_pattern => "logstash-*"
    template => "/usr/share/logstash/templates/logstash.json"
  }

  # Debug output (remove in production)
  # stdout { codec => rubydebug }

  # Send critical errors to dead letter queue
  if "error" in [tags] {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "errors-%{+YYYY.MM.dd}"
    }
  }

  # Send metrics to monitoring
  if [fields][service] == "metrics" {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "metrics-%{+YYYY.MM.dd}"
    }
  }
}